{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train.csv as the main dataset\n",
    "data = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# Column Transformation to lowercase and underscored spaces\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "data.columns = data.columns.str.replace('-', '_')\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "X = data.loc[:, data.columns != 'lead']\n",
    "y = data.loc[:, data.columns == 'lead']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPLITTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(779, 13), (260, 13), (779, 1), (260, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2)\n",
    "[X_train.shape, X_test.shape, y_train.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GET ALL FEATURE COMBINATIONS\n",
    "\n",
    "In this section, we create a function to produce sets of all possible feature combinations and save them in an array to be used in the model iteration. There will be at most $2^{8} = 8192$ (including the empty set) feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to produce an array of all feature combinations\n",
    "def get_all_feature_combinations(data_columns):\n",
    "    from itertools import chain, combinations\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    feature_combinations = list(chain.from_iterable(combinations(data_columns, r) for r in range(len(data_columns)+1)))\n",
    "\n",
    "    feature_combinations_set = []\n",
    "    for feature_combination in feature_combinations:\n",
    "        feature_combination_set = []\n",
    "        for feature in feature_combination:\n",
    "            feature_combination_set.append(feature)\n",
    "        \n",
    "        feature_combinations_set.append(feature_combination_set)\n",
    "\n",
    "    return feature_combinations_set\n",
    "\n",
    "feature_combinations = get_all_feature_combinations(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING FUNCTION\n",
    "\n",
    "In this section, we create a function to find the best K value we could get by iterating thorugh given number of _k_iterations_. The input to this function will be training data **X** and **y** labels.\n",
    "\n",
    "The function will then iterate through _k_iterations_ which takes the data through a **GridSearchCV** pipeline which first scales the training data using **SandardScaler** and then fits a **KNeighborsClassifier** model to provide us the best K value along with it's accuracy.\n",
    "\n",
    "Here, the **GridSearchCV** pipeline handles the cross validation search within itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# A function to produce an array with best K value along with it's accuracy --> eg: returns [K = 10, 0.93]\n",
    "def find_optimal_params_logistic(X, y, n_fold = 10):\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('logreg', LogisticRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'logreg__penalty' : [\"l1\", \"l2\", \"elasticnet\", \"none\"], \n",
    "        'logreg__solver'  : ['newton-cg', 'lbfgs', 'liblinear', \"sag\", \"saga\"]\n",
    "    }   \n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = n_fold, scoring = 'accuracy')\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid_search=grid.fit(X, y.to_numpy().reshape(-1, ))\n",
    "\n",
    "    logreg__penalty = grid_search.best_params_.get('logreg__penalty')\n",
    "    logreg__solver = grid_search.best_params_.get('logreg__solver')\n",
    "    accuracy = grid_search.best_score_\n",
    "\n",
    "    return [logreg__penalty, logreg__solver, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL ITERATOR (PARAMETER TUNING) FUNCTION\n",
    "\n",
    "In this section, we have the code to produce a model performance report for each feature combination. This should ideally be run thorugh all feature combinations (i.e. $2^{8} - 1 = 8191$ excluding the null set), and for each of the feature combination we run the above function **find_best_k_with_accuracy_cv** to give us the best K value along with it's accuracy. For computational convinience, we will be using all feature combinations which includes *at least 9* features for our model iteration.\n",
    "\n",
    "This finally produces a report in csv format, which later can be used as an input for comparing how well each of the K-NN models would perform with an unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OUT OF 100 ITERATIONS COMPLETED - 1.0%\n",
      "2 OUT OF 100 ITERATIONS COMPLETED - 2.0%\n",
      "3 OUT OF 100 ITERATIONS COMPLETED - 3.0%\n",
      "4 OUT OF 100 ITERATIONS COMPLETED - 4.0%\n",
      "5 OUT OF 100 ITERATIONS COMPLETED - 5.0%\n",
      "6 OUT OF 100 ITERATIONS COMPLETED - 6.0%\n",
      "7 OUT OF 100 ITERATIONS COMPLETED - 7.0%\n",
      "8 OUT OF 100 ITERATIONS COMPLETED - 8.0%\n",
      "9 OUT OF 100 ITERATIONS COMPLETED - 9.0%\n",
      "10 OUT OF 100 ITERATIONS COMPLETED - 10.0%\n",
      "11 OUT OF 100 ITERATIONS COMPLETED - 11.0%\n",
      "12 OUT OF 100 ITERATIONS COMPLETED - 12.0%\n",
      "13 OUT OF 100 ITERATIONS COMPLETED - 13.0%\n",
      "14 OUT OF 100 ITERATIONS COMPLETED - 14.0%\n",
      "15 OUT OF 100 ITERATIONS COMPLETED - 15.0%\n",
      "16 OUT OF 100 ITERATIONS COMPLETED - 16.0%\n",
      "17 OUT OF 100 ITERATIONS COMPLETED - 17.0%\n",
      "18 OUT OF 100 ITERATIONS COMPLETED - 18.0%\n",
      "19 OUT OF 100 ITERATIONS COMPLETED - 19.0%\n",
      "20 OUT OF 100 ITERATIONS COMPLETED - 20.0%\n",
      "21 OUT OF 100 ITERATIONS COMPLETED - 21.0%\n",
      "22 OUT OF 100 ITERATIONS COMPLETED - 22.0%\n",
      "23 OUT OF 100 ITERATIONS COMPLETED - 23.0%\n",
      "24 OUT OF 100 ITERATIONS COMPLETED - 24.0%\n",
      "25 OUT OF 100 ITERATIONS COMPLETED - 25.0%\n",
      "26 OUT OF 100 ITERATIONS COMPLETED - 26.0%\n",
      "27 OUT OF 100 ITERATIONS COMPLETED - 27.0%\n",
      "28 OUT OF 100 ITERATIONS COMPLETED - 28.0%\n",
      "29 OUT OF 100 ITERATIONS COMPLETED - 29.0%\n",
      "30 OUT OF 100 ITERATIONS COMPLETED - 30.0%\n",
      "31 OUT OF 100 ITERATIONS COMPLETED - 31.0%\n",
      "32 OUT OF 100 ITERATIONS COMPLETED - 32.0%\n",
      "33 OUT OF 100 ITERATIONS COMPLETED - 33.0%\n",
      "34 OUT OF 100 ITERATIONS COMPLETED - 34.0%\n",
      "35 OUT OF 100 ITERATIONS COMPLETED - 35.0%\n",
      "36 OUT OF 100 ITERATIONS COMPLETED - 36.0%\n",
      "37 OUT OF 100 ITERATIONS COMPLETED - 37.0%\n",
      "38 OUT OF 100 ITERATIONS COMPLETED - 38.0%\n",
      "39 OUT OF 100 ITERATIONS COMPLETED - 39.0%\n",
      "40 OUT OF 100 ITERATIONS COMPLETED - 40.0%\n",
      "41 OUT OF 100 ITERATIONS COMPLETED - 41.0%\n",
      "42 OUT OF 100 ITERATIONS COMPLETED - 42.0%\n",
      "43 OUT OF 100 ITERATIONS COMPLETED - 43.0%\n",
      "44 OUT OF 100 ITERATIONS COMPLETED - 44.0%\n",
      "45 OUT OF 100 ITERATIONS COMPLETED - 45.0%\n",
      "46 OUT OF 100 ITERATIONS COMPLETED - 46.0%\n",
      "47 OUT OF 100 ITERATIONS COMPLETED - 47.0%\n",
      "48 OUT OF 100 ITERATIONS COMPLETED - 48.0%\n",
      "49 OUT OF 100 ITERATIONS COMPLETED - 49.0%\n",
      "50 OUT OF 100 ITERATIONS COMPLETED - 50.0%\n",
      "51 OUT OF 100 ITERATIONS COMPLETED - 51.0%\n",
      "52 OUT OF 100 ITERATIONS COMPLETED - 52.0%\n",
      "53 OUT OF 100 ITERATIONS COMPLETED - 53.0%\n",
      "54 OUT OF 100 ITERATIONS COMPLETED - 54.0%\n",
      "55 OUT OF 100 ITERATIONS COMPLETED - 55.0%\n",
      "56 OUT OF 100 ITERATIONS COMPLETED - 56.0%\n",
      "57 OUT OF 100 ITERATIONS COMPLETED - 57.0%\n",
      "58 OUT OF 100 ITERATIONS COMPLETED - 58.0%\n",
      "59 OUT OF 100 ITERATIONS COMPLETED - 59.0%\n",
      "60 OUT OF 100 ITERATIONS COMPLETED - 60.0%\n",
      "61 OUT OF 100 ITERATIONS COMPLETED - 61.0%\n",
      "62 OUT OF 100 ITERATIONS COMPLETED - 62.0%\n",
      "63 OUT OF 100 ITERATIONS COMPLETED - 63.0%\n",
      "64 OUT OF 100 ITERATIONS COMPLETED - 64.0%\n",
      "65 OUT OF 100 ITERATIONS COMPLETED - 65.0%\n",
      "66 OUT OF 100 ITERATIONS COMPLETED - 66.0%\n",
      "67 OUT OF 100 ITERATIONS COMPLETED - 67.0%\n",
      "68 OUT OF 100 ITERATIONS COMPLETED - 68.0%\n",
      "69 OUT OF 100 ITERATIONS COMPLETED - 69.0%\n",
      "70 OUT OF 100 ITERATIONS COMPLETED - 70.0%\n",
      "71 OUT OF 100 ITERATIONS COMPLETED - 71.0%\n",
      "72 OUT OF 100 ITERATIONS COMPLETED - 72.0%\n",
      "73 OUT OF 100 ITERATIONS COMPLETED - 73.0%\n",
      "74 OUT OF 100 ITERATIONS COMPLETED - 74.0%\n",
      "75 OUT OF 100 ITERATIONS COMPLETED - 75.0%\n",
      "76 OUT OF 100 ITERATIONS COMPLETED - 76.0%\n",
      "77 OUT OF 100 ITERATIONS COMPLETED - 77.0%\n",
      "78 OUT OF 100 ITERATIONS COMPLETED - 78.0%\n",
      "79 OUT OF 100 ITERATIONS COMPLETED - 79.0%\n",
      "80 OUT OF 100 ITERATIONS COMPLETED - 80.0%\n",
      "81 OUT OF 100 ITERATIONS COMPLETED - 81.0%\n",
      "82 OUT OF 100 ITERATIONS COMPLETED - 82.0%\n",
      "83 OUT OF 100 ITERATIONS COMPLETED - 83.0%\n",
      "84 OUT OF 100 ITERATIONS COMPLETED - 84.0%\n",
      "85 OUT OF 100 ITERATIONS COMPLETED - 85.0%\n",
      "86 OUT OF 100 ITERATIONS COMPLETED - 86.0%\n",
      "87 OUT OF 100 ITERATIONS COMPLETED - 87.0%\n",
      "88 OUT OF 100 ITERATIONS COMPLETED - 88.0%\n",
      "89 OUT OF 100 ITERATIONS COMPLETED - 89.0%\n",
      "90 OUT OF 100 ITERATIONS COMPLETED - 90.0%\n",
      "91 OUT OF 100 ITERATIONS COMPLETED - 91.0%\n",
      "92 OUT OF 100 ITERATIONS COMPLETED - 92.0%\n",
      "93 OUT OF 100 ITERATIONS COMPLETED - 93.0%\n",
      "94 OUT OF 100 ITERATIONS COMPLETED - 94.0%\n",
      "95 OUT OF 100 ITERATIONS COMPLETED - 95.0%\n",
      "96 OUT OF 100 ITERATIONS COMPLETED - 96.0%\n",
      "97 OUT OF 100 ITERATIONS COMPLETED - 97.0%\n",
      "98 OUT OF 100 ITERATIONS COMPLETED - 98.0%\n",
      "99 OUT OF 100 ITERATIONS COMPLETED - 99.0%\n",
      "100 OUT OF 100 ITERATIONS COMPLETED - 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Define number of iterations - max 8191\n",
    "iterations = 10\n",
    "\n",
    "# Setting column names for iteration results\n",
    "results_column_names = [\n",
    "        'number_words_female',\n",
    "        'total_words',\n",
    "        'number_of_words_lead',\n",
    "        'difference_in_words_lead_and_co_lead',\n",
    "        'number_of_male_actors',\n",
    "        'year',\n",
    "        'number_of_female_actors',\n",
    "        'number_words_male',\n",
    "        'gross',\n",
    "        'mean_age_male',\n",
    "        'mean_age_female',\n",
    "        'age_lead',\n",
    "        'age_co_lead',\n",
    "        'logreg__penalty',\n",
    "        'logreg__solver',\n",
    "        'accuracy',\n",
    "        'iteration_no'\n",
    "    ]\n",
    "\n",
    "iteration_results = pd.DataFrame(columns=results_column_names)\n",
    "\n",
    "for iteration in range(1, iterations + 1):\n",
    "        if len(feature_combinations[iteration]) >= 1: # Any number within 0 to 13 - based on the minimum # of features we want to include\n",
    "            logreg__penalty, logreg__solver, accuracy = find_optimal_params_logistic(\n",
    "                X_train[feature_combinations[iteration]], y_train, n_fold = 10\n",
    "            )\n",
    "\n",
    "            row = {\n",
    "                'number_words_female': 0,\n",
    "                'total_words': 0,\n",
    "                'number_of_words_lead': 0,\n",
    "                'difference_in_words_lead_and_co_lead': 0,\n",
    "                'number_of_male_actors': 0,\n",
    "                'year': 0,\n",
    "                'number_of_female_actors': 0,\n",
    "                'number_words_male': 0,\n",
    "                'gross': 0,\n",
    "                'mean_age_male': 0,\n",
    "                'mean_age_female': 0,\n",
    "                'age_lead': 0,\n",
    "                'age_co_lead': 0,\n",
    "                'logreg__penalty': logreg__penalty,\n",
    "                'logreg__solver': logreg__solver,\n",
    "                'accuracy': accuracy,\n",
    "                'iteration_no': iteration\n",
    "            }\n",
    "\n",
    "            for key, value in row.items():\n",
    "                if key in feature_combinations[iteration]:\n",
    "                    row[key] = 1\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            iteration_results = iteration_results.append(row, ignore_index=True)\n",
    "            iteration_results.to_csv(r'/Users/dininduseneviratne/Library/CloudStorage/OneDrive-Uppsalauniversitet/Statistical Machine Learning/project-results/logistic_results_8191.csv')\n",
    "            print(str(iteration) + \" OUT OF \" + str(iterations) + \" ITERATIONS COMPLETED - \" + str(iteration*100/iterations) + \"%\")\n",
    "\n",
    "        else: \n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c15b10ab1573516f5b110d1ec5a6cdd301921bf6293fc77ccc4498a93ca5d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
